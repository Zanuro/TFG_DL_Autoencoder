{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('../../Deceptive_Opinion_Spam_Corpus_Datasets/deceptive_training_sin_proc.csv')\n",
    "df_test = pd.read_csv('../../Deceptive_Opinion_Spam_Corpus_Datasets/deceptive_testing_sin_proc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remplazar los truthful con 0 y deceptive con 1 en la columna deceptive\n",
    "df_train = df_train.replace({'deceptive': {'truthful': 0, 'deceptive': 1}})\n",
    "df_test = df_test.replace({'deceptive': {'truthful': 0, 'deceptive': 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dec_a = df_train.iloc[:, 0]\n",
    "#validation_dec_a = validation_set.iloc[:, 0]\n",
    "test_dec_a = df_test.iloc[:, 0]\n",
    "\n",
    "train_dec_a.columns = ['train_dec_a']\n",
    "#validation_dec_a.columns = ['validation_dec_a']\n",
    "test_dec_a.columns = ['test_dec_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     deceptive                                               text\n",
      "0            0  -0.19499199 -0.11689109 -1.0239629 0.589182 -0...\n",
      "1            0  -0.75981146 -0.6247913 -0.5968303 0.8442113 -0...\n",
      "2            0  -0.67143595 -0.34271178 -0.6285268 0.46137583 ...\n",
      "3            0  -0.3716615 -0.6101102 -0.6716857 1.4250252 -0....\n",
      "4            0  0.09419579 0.02537344 -0.07499692 1.4799229 -0...\n",
      "..         ...                                                ...\n",
      "592          0  -0.7387875 -0.31224024 -0.71631956 0.7961637 -...\n",
      "593          0  -0.6691669 -0.8395288 -0.88937396 0.82928854 -...\n",
      "594          0  -0.47775698 -0.21484302 -0.7292124 0.70525247 ...\n",
      "595          0  -0.051372834 -0.48699462 -0.95044464 1.4210202...\n",
      "596          0  -0.71351445 0.17851919 -0.258802 1.0437325 -0....\n",
      "\n",
      "[597 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train = ()\n",
    "y_train = ()\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    res = list(map(float, row['text'].split(' ')))\n",
    "    res = np.asarray(res, dtype=np.float32)\n",
    "    x_train = x_train + (res,)\n",
    "    y_train = y_train + (row['deceptive'],)\n",
    "\n",
    "x_test = ()\n",
    "y_test = ()\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    res = list(map(float, row['text'].split(' ')))\n",
    "    res = np.asarray(res, dtype=np.float32)\n",
    "    x_test = x_test + (res,)\n",
    "    y_test = y_test + (row['deceptive'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "arrays = {}\n",
    "## Train dataset\n",
    "for i in range(0, len(x_train[0])):\n",
    "    col_name = 'value_' + str(i)\n",
    "    arrays[col_name] = numpy.array([item[i] for item in x_train])\n",
    "\n",
    "train_ext = pd.DataFrame(y_train, columns =['deceptive'])\n",
    "\n",
    "for x in arrays.keys(): \n",
    "    dataframe=pd.DataFrame(arrays[x], columns=[x]) \n",
    "    train_ext = train_ext.join(dataframe, how=\"inner\")\n",
    "    \n",
    "train_ext = train_ext.drop(['deceptive'],axis=1)\n",
    "## Test dataset\n",
    "\n",
    "for i in range(0, len(x_test[0])):\n",
    "    col_name = 'value_' + str(i)\n",
    "    arrays[col_name] = numpy.array([item[i] for item in x_test])\n",
    "\n",
    "test_ext = pd.DataFrame(y_test, columns =['deceptive'])\n",
    "\n",
    "for x in arrays.keys(): \n",
    "    dataframe=pd.DataFrame(arrays[x], columns=[x]) \n",
    "    test_ext = test_ext.join(dataframe, how=\"inner\")\n",
    "    \n",
    "test_ext = test_ext.drop(['deceptive'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train, y_train = np.asarray(x_train), np.asarray(y_train)\n",
    "#x_validation, y_validation = np.asarray(x_validation), np.asarray(y_validation)\n",
    "x_test, y_test = np.asarray(x_test), np.asarray(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "#x_validation = x_validation.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (597, 300)\n",
      "Test data shape: (198, 300)\n"
     ]
    }
   ],
   "source": [
    "# reshape inputs for LSTM [samples, timesteps, features]\n",
    "X_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1]) # X_train \n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "#x_validation = x_validation.reshape(x_validation.shape[0], 1, x_validation.shape[1]) # X_train \n",
    "#print(\"Validation data shape:\", x_validation.shape)\n",
    "X_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])     # X_test \n",
    "print(\"Test data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.19499199 -0.11689109 -1.0239629  ... -0.3362849   0.09603526\n",
      "   -0.29484585]]\n",
      "\n",
      " [[-0.75981146 -0.6247913  -0.5968303  ...  0.20598556 -0.4579486\n",
      "    0.02073733]]\n",
      "\n",
      " [[-0.67143595 -0.34271178 -0.6285268  ... -0.49001852 -0.4839096\n",
      "    0.07291023]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.47775698 -0.21484302 -0.7292124  ...  0.11411288  0.13427125\n",
      "    0.22181219]]\n",
      "\n",
      " [[-0.05137283 -0.48699462 -0.95044464 ... -0.8822731  -0.40317678\n",
      "    0.25194392]]\n",
      "\n",
      " [[-0.71351445  0.17851919 -0.258802   ...  0.2708312  -0.08303961\n",
      "   -0.6212692 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "!pip install -q -U keras-tuner\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aparte del modelo vamos a definir los hiperparametros construyendo el hypermodelo\n",
    "## Vamos a utilizar o bien una funccion builder o utilizar una subclase HyperModel usando la Keras Tuner \n",
    "\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, Reshape, Conv2DTranspose, LSTM, TimeDistributed, RepeatVector, Dropout\n",
    "from tensorflow.keras import models, layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as BE\n",
    "from keras import regularizers\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner import Hyperband\n",
    "from kerastuner import BayesianOptimization\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class RegressionHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            layers.LSTM(300,\n",
    "                #units=hp.Int('units', 8, 64, 4, default=8),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )\n",
    "\n",
    "        L1=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_2', min_value=16, max_value=256, step=16), # 'units_2', 16, 32, 64, default=32),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                    kernel_regularizer=regularizers.l2(hp.Choice('regularizers.l2', values=[0.00, 0.01, 0.05, 0.1])), # Valorarlo... \n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        ) \n",
    "        \n",
    "        L2=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_3', min_value=2, max_value=32, step=2),              #'units_3', 2, 4, 8, default=4\n",
    "                activation=hp.Choice( \n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )  \n",
    "        \n",
    "        \n",
    "        L3=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_4', min_value=2, max_value=32, step=2),              #'units_3', 2, 4, 8, default=4\n",
    "                activation=hp.Choice( \n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        ) \n",
    "        \n",
    "        L4=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_5', min_value=16, max_value=256, step=16),        #'units_4', 16, 32, 64, default=32\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            layers.Dropout(\n",
    "                hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.1,\n",
    "                    default=0.005,\n",
    "                    step=0.01)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(layers.Dense(300))\n",
    "        optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop','nadam', 'adadelta',\n",
    "                                            'adagrad', 'adamax','ftrl'])\n",
    "        model.compile(\n",
    "            optimizer=optimizer,loss='mse',metrics=['mse']\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1],X_train.shape[2],)\n",
    "hypermodel = RegressionHyperModel(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs = RandomSearch(\n",
    "            hypermodel,\n",
    "            objective='mse',\n",
    "            seed=10,\n",
    "            max_trials= 10,\n",
    "            directory='keras-tuner-deceptive',\n",
    "            project_name='deceptive-opinion-keras',\n",
    "            executions_per_trial=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.search(X_train, X_train, epochs=50, validation_split = 0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "mse_rs = model.evaluate(X_test, X_test)[1]\n",
    "print('Random search MSE: ', mse_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb = Hyperband(\n",
    "            hypermodel,\n",
    "            max_epochs= 20,\n",
    "            objective='mse',\n",
    "            seed=100,\n",
    "            overwrite=True,\n",
    "            executions_per_trial=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_hb.search(X_train, X_train, epochs= 100, validation_split = 0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner_hb.get_best_models(num_models=1)[0]\n",
    "mse_hb = best_model.evaluate(X_test, X_test)[1]\n",
    "print('Hyperband Optimization MSE: ', mse_hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo = BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective='mse',\n",
    "            max_trials=10,\n",
    "            seed=10,\n",
    "            overwrite=True,\n",
    "            executions_per_trial=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.search(X_train, X_train, epochs=100, validation_split = 0.2, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.get_best_models(num_models=1)[0]\n",
    "tuner_bo.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner_bo.get_best_models(num_models=1)[0]\n",
    "mse_bo = model.evaluate(x_train, x_train)[1]\n",
    "print('Bayesian Optimization MSE: ', mse_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results for Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.get_best_models()[0].summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
