{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit129eeb57289c44939b4863da13de07dc",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      deceptive             hotel  polarity       source  \\\n0      truthful            conrad  positive  TripAdvisor   \n1      truthful             hyatt  positive  TripAdvisor   \n2      truthful             hyatt  positive  TripAdvisor   \n3      truthful              omni  positive  TripAdvisor   \n4      truthful             hyatt  positive  TripAdvisor   \n...         ...               ...       ...          ...   \n1595  deceptive  intercontinental  negative        MTurk   \n1596  deceptive            amalfi  negative        MTurk   \n1597  deceptive  intercontinental  negative        MTurk   \n1598  deceptive            palmer  negative        MTurk   \n1599  deceptive            amalfi  negative        MTurk   \n\n                                                   text  \n0     We stayed for a one night getaway with family ...  \n1     Triple A rate with upgrade to view room was le...  \n2     This comes a little late as I'm finally catchi...  \n3     The Omni Chicago really delivers on all fronts...  \n4     I asked for a high floor away from the elevato...  \n...                                                 ...  \n1595  Problems started when I booked the InterContin...  \n1596  The Amalfi Hotel has a beautiful website and i...  \n1597  The Intercontinental Chicago Magnificent Mile ...  \n1598  The Palmer House Hilton, while it looks good i...  \n1599  As a former Chicagoan, I'm appalled at the Ama...  \n\n[1600 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "## Load data from a csv file, pre-process the content of it and then generate the training and test dataset\n",
    "## Cargar datos desde un fichero csv, preprocesar sus contenidos y generar el dataset de entreno y testing\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = pd.read_csv('/home/zan/Downloads/deceptive-opinion.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  deceptive   hotel  polarity       source  \\\n",
       "0  truthful  conrad  positive  TripAdvisor   \n",
       "1  truthful   hyatt  positive  TripAdvisor   \n",
       "2  truthful   hyatt  positive  TripAdvisor   \n",
       "3  truthful    omni  positive  TripAdvisor   \n",
       "4  truthful   hyatt  positive  TripAdvisor   \n",
       "\n",
       "                                                text  \n",
       "0  We stayed for a one night getaway with family ...  \n",
       "1  Triple A rate with upgrade to view room was le...  \n",
       "2  This comes a little late as I'm finally catchi...  \n",
       "3  The Omni Chicago really delivers on all fronts...  \n",
       "4  I asked for a high floor away from the elevato...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deceptive</th>\n      <th>hotel</th>\n      <th>polarity</th>\n      <th>source</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>truthful</td>\n      <td>conrad</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>We stayed for a one night getaway with family ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>truthful</td>\n      <td>hyatt</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>Triple A rate with upgrade to view room was le...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>truthful</td>\n      <td>hyatt</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>This comes a little late as I'm finally catchi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>truthful</td>\n      <td>omni</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>The Omni Chicago really delivers on all fronts...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>truthful</td>\n      <td>hyatt</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>I asked for a high floor away from the elevato...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      deceptive             hotel  polarity       source  \\\n",
       "0      truthful            conrad  positive  TripAdvisor   \n",
       "1      truthful             hyatt  positive  TripAdvisor   \n",
       "2      truthful             hyatt  positive  TripAdvisor   \n",
       "3      truthful              omni  positive  TripAdvisor   \n",
       "4      truthful             hyatt  positive  TripAdvisor   \n",
       "...         ...               ...       ...          ...   \n",
       "1595  deceptive  intercontinental  negative        MTurk   \n",
       "1596  deceptive            amalfi  negative        MTurk   \n",
       "1597  deceptive  intercontinental  negative        MTurk   \n",
       "1598  deceptive            palmer  negative        MTurk   \n",
       "1599  deceptive            amalfi  negative        MTurk   \n",
       "\n",
       "                                                   text  \n",
       "0     We stayed for a one night getaway with family ...  \n",
       "1     Triple A rate with upgrade to view room was le...  \n",
       "2     This comes a little late as I'm finally catchi...  \n",
       "3     The Omni Chicago really delivers on all fronts...  \n",
       "4     I asked for a high floor away from the elevato...  \n",
       "...                                                 ...  \n",
       "1595  Problems started when I booked the InterContin...  \n",
       "1596  The Amalfi Hotel has a beautiful website and i...  \n",
       "1597  The Intercontinental Chicago Magnificent Mile ...  \n",
       "1598  The Palmer House Hilton, while it looks good i...  \n",
       "1599  As a former Chicagoan, I'm appalled at the Ama...  \n",
       "\n",
       "[1596 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deceptive</th>\n      <th>hotel</th>\n      <th>polarity</th>\n      <th>source</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>truthful</td>\n      <td>conrad</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>We stayed for a one night getaway with family ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>truthful</td>\n      <td>hyatt</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>Triple A rate with upgrade to view room was le...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>truthful</td>\n      <td>hyatt</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>This comes a little late as I'm finally catchi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>truthful</td>\n      <td>omni</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>The Omni Chicago really delivers on all fronts...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>truthful</td>\n      <td>hyatt</td>\n      <td>positive</td>\n      <td>TripAdvisor</td>\n      <td>I asked for a high floor away from the elevato...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>deceptive</td>\n      <td>intercontinental</td>\n      <td>negative</td>\n      <td>MTurk</td>\n      <td>Problems started when I booked the InterContin...</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>deceptive</td>\n      <td>amalfi</td>\n      <td>negative</td>\n      <td>MTurk</td>\n      <td>The Amalfi Hotel has a beautiful website and i...</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>deceptive</td>\n      <td>intercontinental</td>\n      <td>negative</td>\n      <td>MTurk</td>\n      <td>The Intercontinental Chicago Magnificent Mile ...</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>deceptive</td>\n      <td>palmer</td>\n      <td>negative</td>\n      <td>MTurk</td>\n      <td>The Palmer House Hilton, while it looks good i...</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>deceptive</td>\n      <td>amalfi</td>\n      <td>negative</td>\n      <td>MTurk</td>\n      <td>As a former Chicagoan, I'm appalled at the Ama...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1596 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "## Replace missing values & eliminate duplicated values/etc.\n",
    "## Sustituir valores nulos/missing y eliminar valores duplicados \n",
    "missing_values = [\"n/a\", \"na\", \"--\"]\n",
    "df.isnull().sum() ## No hay valores de tipo missing\n",
    "df[df.duplicated(keep=False)] ## 803-853, 847-862,  995-1014, 1085-1109\n",
    "df = df.drop_duplicates() ## Hay cuatro duplicados en el dataset\n",
    "df\n",
    "\n",
    "\n",
    "#df.iloc[803] == df.iloc[853]\n",
    "#df.iloc[803].equals(df.iloc[853])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  deceptive                                               text\n",
       "0  truthful  We stayed for a one night getaway with family ...\n",
       "1  truthful  Triple A rate with upgrade to view room was le...\n",
       "2  truthful  This comes a little late as I'm finally catchi...\n",
       "3  truthful  The Omni Chicago really delivers on all fronts...\n",
       "4  truthful  I asked for a high floor away from the elevato..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deceptive</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>truthful</td>\n      <td>We stayed for a one night getaway with family ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>truthful</td>\n      <td>Triple A rate with upgrade to view room was le...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>truthful</td>\n      <td>This comes a little late as I'm finally catchi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>truthful</td>\n      <td>The Omni Chicago really delivers on all fronts...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>truthful</td>\n      <td>I asked for a high floor away from the elevato...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "## Eliminate columns -- 1-3 as they won't contribute to the model\n",
    "## Eliminar columnas del 1 al 3 ya que no aportan informacion adiccional al modelo\n",
    "\n",
    "df = df.drop(df.columns[[1, 2, 3]], axis = 1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "796\n800\n"
     ]
    }
   ],
   "source": [
    "## The deceptive and truthful registers are balanced: 800 - 800\n",
    "## La clase deceptive esta balaneceada, tiene 800 registros deceptive y 800 registros truthful\n",
    "print(len(df[df['deceptive'] == 'truthful']))\n",
    "print(len(df[df['deceptive'] == 'deceptive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limpiar texto, opinion del usuario para luego poder convertir la secuencia a vector\n",
    "\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate training and testing dataset\n",
    "training_split = 0.75\n",
    "testing_split = 0.25\n",
    "pos_testing_split = 0.9 ## truthful + deceptive, los deceptive entre 5-10% de esta suma.\n",
    "neg_deceptive_split = 0.1\n",
    "\n",
    "deceptive_training = df[df.deceptive == 'truthful'].sample(frac = training_split)\n",
    "newdf = df.drop(deceptive_training.index.values)\n",
    "pos_deceptive_testing = newdf[newdf.deceptive == 'truthful'].sample(frac = pos_testing_split)\n",
    "neg_deceptive_testing = newdf[newdf.deceptive == 'deceptive'].sample(int(neg_deceptive_split * (testing_split * len(df[df.deceptive == 'truthful']))))\n",
    "\n",
    "frames = [pos_deceptive_testing, neg_deceptive_testing]\n",
    "deceptive_testing = pd.concat(frames)\n",
    "deceptive_testing = deceptive_testing.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLTK tokenizer\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2: ## solo las palabras con longitud > 2\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "train_dec = deceptive_training.apply(\n",
    "    lambda x: TaggedDocument(words=tokenize_text(x['text']), tags=[x.deceptive]), axis=1)\n",
    "test_dec = deceptive_testing.apply(\n",
    "    lambda x: TaggedDocument(words=tokenize_text(x['text']), tags=[x.deceptive]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1290056.41it/s]\n"
     ]
    }
   ],
   "source": [
    "## Build vocabulary using distributed bag of words\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "dbow = Doc2Vec(dm=0, vector_size = 300, negative=5, hs=0, min_count = 2, sample = 0, workers = cores)\n",
    "dbow.build_vocab([x for x in tqdm(train_dec.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1453278.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2377967.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2371211.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2143835.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2576131.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1532435.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2009630.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1257659.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1315816.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 910876.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2239713.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 908562.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 940999.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2225777.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1557213.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1902735.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1304846.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1199233.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2227757.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1480780.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1231071.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1751048.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1729281.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1460909.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2011244.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1421112.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2134696.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 2025889.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1116859.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 597/597 [00:00<00:00, 1150206.47it/s]\n",
      "CPU times: user 3.62 s, sys: 283 ms, total: 3.9 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import utils\n",
    "for epoch in range(30):\n",
    "    dbow.train(utils.shuffle([x for x in tqdm(train_dec.values)]), total_examples=len(train_dec.values), epochs=1)\n",
    "    dbow.alpha -= 0.002\n",
    "    dbow.min_alpha = dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, x_train = vec_for_learning(dbow, train_dec)\n",
    "y_test, x_test = vec_for_learning(dbow, test_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     deceptive                                               text\n",
       "7    deceptive  [-0.7016574, -0.94312495, -0.8534526, -0.51577...\n",
       "34   deceptive  [-0.7011773, -0.9411192, -0.8525701, -0.515268...\n",
       "46   deceptive  [-0.7012025, -0.9420752, -0.85128146, -0.51399...\n",
       "63   deceptive  [-0.69915825, -0.9389035, -0.8508887, -0.51393...\n",
       "78   deceptive  [-0.700142, -0.94085497, -0.8530075, -0.516346...\n",
       "85   deceptive  [-0.70387024, -0.9441721, -0.85560876, -0.5174...\n",
       "87   deceptive  [-0.7010671, -0.9403878, -0.8513633, -0.514217...\n",
       "92   deceptive  [-0.6995749, -0.9368511, -0.8495235, -0.514266...\n",
       "99   deceptive  [-0.6999097, -0.9438077, -0.8538104, -0.515506...\n",
       "106  deceptive  [-0.69828856, -0.939626, -0.85000527, -0.51486...\n",
       "112  deceptive  [-0.7002405, -0.9411909, -0.8520088, -0.514117...\n",
       "126  deceptive  [-0.69852924, -0.9392565, -0.85053504, -0.5135...\n",
       "127  deceptive  [-0.6964617, -0.9370468, -0.84900934, -0.51227...\n",
       "131  deceptive  [-0.7013647, -0.94251496, -0.8525952, -0.51439...\n",
       "133  deceptive  [-0.69880646, -0.93924475, -0.85143155, -0.515...\n",
       "154  deceptive  [-0.70046836, -0.9390002, -0.85057634, -0.5143...\n",
       "185  deceptive  [-0.699748, -0.94044226, -0.8537449, -0.516051...\n",
       "187  deceptive  [-0.69991225, -0.9418817, -0.85308903, -0.5157...\n",
       "192  deceptive  [-0.70231974, -0.9411, -0.85265553, -0.514851,..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deceptive</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>deceptive</td>\n      <td>[-0.7016574, -0.94312495, -0.8534526, -0.51577...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>deceptive</td>\n      <td>[-0.7011773, -0.9411192, -0.8525701, -0.515268...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>deceptive</td>\n      <td>[-0.7012025, -0.9420752, -0.85128146, -0.51399...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>deceptive</td>\n      <td>[-0.69915825, -0.9389035, -0.8508887, -0.51393...</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>deceptive</td>\n      <td>[-0.700142, -0.94085497, -0.8530075, -0.516346...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>deceptive</td>\n      <td>[-0.70387024, -0.9441721, -0.85560876, -0.5174...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>deceptive</td>\n      <td>[-0.7010671, -0.9403878, -0.8513633, -0.514217...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>deceptive</td>\n      <td>[-0.6995749, -0.9368511, -0.8495235, -0.514266...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>deceptive</td>\n      <td>[-0.6999097, -0.9438077, -0.8538104, -0.515506...</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>deceptive</td>\n      <td>[-0.69828856, -0.939626, -0.85000527, -0.51486...</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>deceptive</td>\n      <td>[-0.7002405, -0.9411909, -0.8520088, -0.514117...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>deceptive</td>\n      <td>[-0.69852924, -0.9392565, -0.85053504, -0.5135...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>deceptive</td>\n      <td>[-0.6964617, -0.9370468, -0.84900934, -0.51227...</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>deceptive</td>\n      <td>[-0.7013647, -0.94251496, -0.8525952, -0.51439...</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>deceptive</td>\n      <td>[-0.69880646, -0.93924475, -0.85143155, -0.515...</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>deceptive</td>\n      <td>[-0.70046836, -0.9390002, -0.85057634, -0.5143...</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>deceptive</td>\n      <td>[-0.699748, -0.94044226, -0.8537449, -0.516051...</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>deceptive</td>\n      <td>[-0.69991225, -0.9418817, -0.85308903, -0.5157...</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>deceptive</td>\n      <td>[-0.70231974, -0.9411, -0.85265553, -0.514851,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_list = []\n",
    "for tag, text_val in zip(y_train, x_train):\n",
    "    training_list.append([tag,text_val])\n",
    "\n",
    "testing_list = []\n",
    "for tag, text_val in zip(y_test, x_test):\n",
    "    testing_list.append([tag,text_val])\n",
    "\n",
    "deceptive_training = pd.DataFrame(data=training_list, columns=[\"deceptive\",\"text\"])\n",
    "deceptive_testing = pd.DataFrame(data=testing_list, columns=[\"deceptive\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "deceptive_training.to_csv(r'/home/zan/Desktop/dl_autoencoder/docs/autoencoder/deceptive_opinion_autoencoder/deceptive_training.csv', index=False)\n",
    "deceptive_testing.to_csv(r'/home/zan/Desktop/dl_autoencoder/docs/autoencoder/deceptive_opinion_autoencoder/deceptive_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}