{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.externals import joblib\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, cohen_kappa_score, fbeta_score\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve, log_loss\n",
    "LABELS = [\"Normal\",\"FMA\"]\n",
    "\n",
    "#set up graphic style in this case I am using the color scheme from xkcd.com\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 8.7 # Golden Mean\n",
    "col_list = [\"cerulean\",\"scarlet\"]# https://xkcd.com/color/rgb/\n",
    "sns.set(style='white', font_scale=1.75, palette=sns.xkcd_palette(col_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "# set random seed\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import HyperModel\n",
    "from kerastuner import Hyperband\n",
    "from kerastuner import BayesianOptimization\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras import models, layers\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar training y testing\n",
    "# Read in data and display first 5 rows\n",
    "test = pd.read_csv(\"Dataset_Test.csv\")\n",
    "# validation\n",
    "train = pd.read_csv(\"Dataset_Training.csv\")\n",
    "print('The shape of our train is:', train.shape)\n",
    "#test.head(5)\n",
    "#train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['FMA'] == 0] # Seleccion de datos\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 1460 # Validation\n",
    "validation = train[-split:]\n",
    "train = train[:-split]\n",
    "# The last element contains the labels\n",
    "# Convertir Series to DataFrame (.to_frame())\n",
    "train_fma = train.iloc[:, -1]\n",
    "validation_fma = validation.iloc[:, -1]\n",
    "test_fma = test.iloc[:, -1]\n",
    "\n",
    "# Columnas\n",
    "train_fma.columns = ['train_fma']\n",
    "validation_fma.columns = ['validation_fma']\n",
    "test_fma.columns = ['test_fma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar Campos\n",
    "#test = test.drop(['temp_avg','temp_min', 'atmos_pres_min', 'wd', 'atmos_pres_max','atmos_pres_avg', 'rh','ceil_hgt', 'visibility', 'FMA'], axis=1) \n",
    "# ceil_hgt # visibility ,'temp_max','temp_min'\n",
    "test = test.drop(['atmos_pres_min', 'atmos_pres_max','ceil_hgt', 'visibility', 'FMA'], axis=1)\n",
    "\n",
    "# Eliminar Campos\n",
    "#train = train.drop(['temp_avg','temp_min', 'atmos_pres_min', 'wd', 'atmos_pres_max','atmos_pres_avg', 'rh','ceil_hgt', 'visibility', 'FMA'], axis=1)\n",
    "train = train.drop(['atmos_pres_min', 'atmos_pres_max','ceil_hgt', 'visibility', 'FMA'], axis=1)\n",
    "\n",
    "# Eliminar Campos\n",
    "#validation = validation.drop(['temp_avg','temp_min', 'atmos_pres_min', 'wd', 'atmos_pres_max','atmos_pres_avg', 'rh','ceil_hgt', 'visibility', 'FMA'], axis=1)\n",
    "validation = validation.drop(['atmos_pres_min', 'atmos_pres_max','ceil_hgt', 'visibility', 'FMA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training dataset shape:\", train.shape)\n",
    "print(\"Test dataset shape:\", validation.shape)\n",
    "print(\"Test dataset shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data or Standardize the data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(train)\n",
    "X_test = scaler.transform(test)\n",
    "X_validation = scaler.transform(validation)\n",
    "scaler_filename = \"scaler_data\"\n",
    "joblib.dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing - normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "x_train_scaled = scaler.transform(train)\n",
    "x_test_scaled = scaler.transform(test)\n",
    "x_validation_scaled = scaler.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape inputs for LSTM [samples, timesteps, features]\n",
    "x_train_scaled = x_train_scaled.reshape(x_train_scaled.shape[0], 1, X_train.shape[1]) # X_train \n",
    "print(\"Training data shape:\", x_train_scaled.shape)\n",
    "x_test_scaled = x_test_scaled.reshape(x_test_scaled.shape[0], 1, x_test_scaled.shape[1])     # X_test \n",
    "print(\"Test data shape:\", x_test_scaled.shape)\n",
    "x_validation_scaled = x_validation_scaled.reshape(x_validation_scaled.shape[0], 1, x_validation_scaled.shape[1])  #X_validation\n",
    "print(\"Test data shape:\", x_validation_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            layers.LSTM(8,\n",
    "                #units=hp.Int('units', 8, 64, 4, default=8),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        L1=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_2', min_value=16, max_value=512, step=16), # 'units_2', 16, 32, 64, default=32),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                    kernel_regularizer=regularizers.l2(hp.Choice('regularizers.l2', values=[0.00, 0.01, 0.05, 0.1])), # Valorarlo... \n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        ) \n",
    "        \n",
    "        L2=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_3', min_value=2, max_value=8, step=1),              #'units_3', 2, 4, 8, default=4\n",
    "                activation=hp.Choice( \n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )  \n",
    "        \n",
    "        \n",
    "        L3=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_4', min_value=2, max_value=8, step=1),              #'units_3', 2, 4, 8, default=4\n",
    "                activation=hp.Choice( \n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        ) \n",
    "        \n",
    "        L4=model.add(\n",
    "            layers.LSTM(\n",
    "                units=hp.Int('units_5', min_value=32, max_value=512, step=16),        #'units_4', 16, 32, 64, default=32\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                return_sequences=True,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            layers.Dropout(\n",
    "                hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.1,\n",
    "                    default=0.005,\n",
    "                    step=0.01)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(layers.Dense(8))\n",
    "        optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop','nadam', 'adadelta',\n",
    "                                            'adagrad', 'adamax','ftrl'])\n",
    "        model.compile(\n",
    "            optimizer=optimizer,loss='mse',metrics=['mse']\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciar HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train_scaled.shape[1],x_train_scaled.shape[2],)\n",
    "hypermodel = RegressionHyperModel(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs = RandomSearch(\n",
    "            hypermodel,\n",
    "            objective='mse',\n",
    "            seed=42,\n",
    "            max_trials= 10, # 20\n",
    "            project_name='helloworld',\n",
    "            overwrite=True,\n",
    "            executions_per_trial=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.search(x_train_scaled, x_train_scaled, epochs=20, validation_data=(x_validation_scaled, x_validation_scaled), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "loss, mse = best_model.evaluate(x_test_scaled, x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "loss, mse = best_model.evaluate(x_train_scaled, x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "mse_rs = best_model.evaluate(x_test_scaled, x_test_scaled)[1]\n",
    "print('Random search MSE: ', mse_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperbanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb = Hyperband(\n",
    "            hypermodel,\n",
    "            max_epochs= 20,\n",
    "            objective='mse',\n",
    "            seed=42,\n",
    "            overwrite=True,\n",
    "            executions_per_trial=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb.search(x_train_scaled, x_train_scaled, epochs= 100, validation_data=(x_validation_scaled, x_validation_scaled), verbose=0) # y_train\n",
    "best_model = tuner_hb.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(x_test_scaled, x_test_scaled) # y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner_hb.get_best_models(num_models=1)[0]\n",
    "mse_hb = best_model.evaluate(x_test_scaled, x_test_scaled)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hyperband Optimization MSE: ', mse_hb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo = BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective='mse',\n",
    "            max_trials=2,\n",
    "            seed=42,\n",
    "            overwrite=True,\n",
    "            executions_per_trial=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.search(x_train_scaled, x_train_scaled, epochs=100, validation_data=(x_validation_scaled, x_validation_scaled), verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner_bo.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(x_test_scaled, x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner_bo.get_best_models(num_models=1)[0]\n",
    "mse_bo = best_model.evaluate(x_test_scaled, x_test_scaled)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bayesian Optimization MSE: ', mse_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hyperband Optimization MSE: ', mse_hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random search MSE: ', mse_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_hb.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}